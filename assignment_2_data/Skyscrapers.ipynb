{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "variadic keyword parameters cannot have default values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9622d59f11d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martist\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mArtist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m     62\u001b[0m     \u001b[0mAbstract\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mrender\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mFigureCanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mArtist\u001b[1;34m()\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delete_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"3.3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"args\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delete_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"3.3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"kwargs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         \"\"\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36m_delete_parameter\u001b[1;34m(since, name, func)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32melse\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         for param in signature.parameters.values()])\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32melse\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         for param in signature.parameters.values()])\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, name, kind, annotation, default)\u001b[0m\n\u001b[0;32m   2547\u001b[0m             \u001b[0mdefault\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2549\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mannotation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[0;32m   2474\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{} parameters cannot have default values'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2475\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_paramkind_descr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2476\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2477\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2478\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_annotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: variadic keyword parameters cannot have default values"
     ]
    }
   ],
   "source": [
    "import geocoder\n",
    "from geopandas import GeoDataFrame\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Skyscraper Index (https://en.wikipedia.org/wiki/Skyscraper_Index) is sometimes used as a metric for determining the status of an economy, in particular, predicting when there will be an economic downturn.  The premise is that the tallest skyscrapers are built during times of economic growth, and this stops as the economy goes into recession.  There will be a lag, however, as construction projects are often finalised years in advance, contracts signed, and significant amounts of money have already been paid.  \n",
    "\n",
    "You are going to investigate whether there is any evidence of the Skyscraper Index working empirically.\n",
    "\n",
    "I have created a dataset containing 6000 skyscrapers.  This contains the name of the building, the city, the height in metres (and feet), the number of floors, the year of completion (or cancellation), and the status of the building (completed, under construction, cancelled, etc.).  \n",
    "\n",
    "The dataset has been augmented by geocoding the cities and buildings.  The country, and the latitude and longitude of the city have been added.  The geocoding was done using OpenStreetMaps, which is free and community sourced - the accuracy of the data is not guaranteed.  In particular, the country names are returned in the official language of the country, and not English. \n",
    "\n",
    "This augmented dataset has been *partially* cleaned.  The country names have been converted to English, some missing fields have been added, and datatypes have been updated.  Each step of the cleaning is detailed in the notebook below. \n",
    "\n",
    "The Index also requires GDP data.  I have sourced a dataset for you from TODO, which contains several GDP metrics per country.  I have done some basic cleaning on the dataset too - something you will notice is that the country names do not align exactly with this dataset and the skyscraper dataset.  This is a normal problem you will run into when merging two disparate datasets.  I have detailed how I went about merging this, but it was a manual, once-off process.  \n",
    "\n",
    "\n",
    "Questions: \n",
    "* For the buildings in the USA, create a chloropleth with the average height of all completed skyscrapers per state.  Hint:  look at the python osmnx package to do this. \n",
    "* Europe has relatively few skyscrapers, but their GDP per capita is high.  Look at the number of skyscrapers in Germany, France, UK, Switzerland, and the Netherlands.  Then compare this against the UAE, Japan, and the USA.  Can you provide a reason for why this is the case? \n",
    "* Look at the following 5 countries: SA, USA, UK, UAE, China.\n",
    "* Look at the GDP per capita for these countries and plot this against a) the tallest building per year, b) the number of new skyscrapers built in a year, c) the number of cancelled buildings in a year.  \n",
    "** Is there any obvious correlation between GDP and a), b) and c)?  You do not need to do any statistical tests - a couple of sentences is fine, just back it up with the data in the plot.  Any correlation metrics or plots would be beneficial.  Hint: look at the GDP *growth* as well. \n",
    "    ** Missing data: Not all buildings have a height.  How else can you show the height of the building?  \n",
    "* For the chosen countries, find out when they had recessions, and add this as an additional point on the plot (single datapoint, you do not have to indicate the full length of the recession).  Is there any trend or correlation between the skyscraper data and the recessions?  As above, you only need to provide a written answer with motivation (and the source for the recession data - Wikipedia is fine).\n",
    "* Of the 5 countries, 1 of the countries shows behaviour that is completely at odds with the Skyscraper Index.  Which one is it?  Any idea why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skyscraper data:\n",
    "\n",
    "I have sourced this from https://en.phorio.com/?t=projectlist&collection=5495651&type=list.  You can try web-scraping it, but I scrolled down until there were 6000 results, and then copied the text into a text file, and wrote a small python script to clean it up for me and create a csv - see attached python script for the details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('skyscrapers6000_clean.csv')\n",
    "df.dropna(axis=0, subset=['City'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the city, but not the country or coordinates.  I have geocoded these using the python package `geocoder`.  If you have an API key for Google or Bing maps, you can geocode with those services, but it is not free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_states():\n",
    "    state_lookup = {}\n",
    "    if os.path.exists('state_lookup.csv'):\n",
    "        with open('state_lookup.csv', encoding=\"utf8\") as fi:\n",
    "            for ll in fi.readlines()[1:]:\n",
    "                c,s = ll.strip().split(',')\n",
    "                state_lookup[c] = s\n",
    "        return state_lookup\n",
    "    \n",
    "    for city in df[df.Country == 'United States of America']['City'].unique():\n",
    "        print(city)\n",
    "        if city in state_lookup.keys():\n",
    "            continue\n",
    "        c = geocoder.osm(city)\n",
    "        if not c.ok: \n",
    "            continue\n",
    "        state_lookup[city] = c.state\n",
    "\n",
    "    with open('state_lookup.csv', 'w', encoding=\"utf8\") as fo:\n",
    "        fo.write('city,state\\n')\n",
    "        for c, s in state_lookup.items():\n",
    "            fo.write(c + ',' + s + '\\n')\n",
    "    return state_lookup\n",
    "\n",
    "\n",
    "def geocode_it():\n",
    "    city_lookup = {}\n",
    "    # if the geocoding has already been done, just read in the file.\n",
    "    if os.path.exists('city_lookup.csv'):\n",
    "        with open('city_lookup.csv', 'r', encoding=\"utf8\") as fi:\n",
    "            for ci in fi.readlines()[1:]:\n",
    "                city, cntry, lat, lon, cntry_eng = ci.strip().split(',')\n",
    "                city_lookup[city] = {\n",
    "                    'Country': cntry,\n",
    "                    'Latitude': float(lat),\n",
    "                    'Longitude': float(lon)\n",
    "                }\n",
    "        return city_lookup\n",
    "\n",
    "    counter = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if counter % 100 == 0:\n",
    "            print(counter)\n",
    "        counter += 1\n",
    "        city = row['City']\n",
    "        # do not geocode a city that has been geocoded already\n",
    "        if city in city_lookup.keys():\n",
    "            continue\n",
    "\n",
    "        bldg = row['Building']\n",
    "        g = geocoder.osm(city)\n",
    "        # if it could not find details for the city only, then try adding in the building name too.\n",
    "        if not g.ok:\n",
    "            print('could not get country for ', city, 'trying with building')\n",
    "            g = geocoder.osm(bldg + ', ' + city)\n",
    "            if not g.ok:\n",
    "                print('could not get country for ', city, bldg)\n",
    "                \n",
    "        city_lookup[city] = {'Country': g.country, 'Latitude': g.latlng[0], 'Longitude': g.latlng[1]}\n",
    "\n",
    "    # save the output so that next time we don't have to do all the geocoding again! \n",
    "    with open('city_lookup.csv', 'w', encoding=\"utf8\") as fo:\n",
    "        fo.write('city,country,latitude,longitude\\n')\n",
    "        for city, vals in city_lookup.items():\n",
    "            fo.write(str(city) + ',' + str(vals['Country']) +',' + str(vals['Latitude']) + ',' + str(vals['Longitude']) + '\\n')\n",
    "\n",
    "    return city_lookup\n",
    "\n",
    "city_lookup = geocode_it()\n",
    "state_lookup = get_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the unique country names, you'll notice that they are not in English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = list(set([x['Country'] for x in city_lookup.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is where you have to do a bit of digging in the data exploration process.  I created a dictionary with the translation to English - where it was not obvious to me, I used Google Translate to get the translation (eg. for Pakistan, South Korea and North Korea). \n",
    "\n",
    "Note here name for Taiwan.  This is a contentious political issue...  For the mapping between the skyscraper dataset and the GDP dataset, we are going to include Taiwan as part of China. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_names = {\n",
    "    '북조선': 'North Korea',\n",
    "    'قطر Qatar': 'Qatar',\n",
    "    'Saudi Arabia / السعودية': 'Saudi Arabia',\n",
    "    'Česká republika': 'Czech Republic',\n",
    "    'República Dominicana': 'Dominican Republic',\n",
    "    'Magyarország': 'Hungary',\n",
    "    'Norge': 'Norway',\n",
    "    'Polska': 'Poland',\n",
    "    'België - Belgique - Belgien': 'Belgium',\n",
    "    'پاکستان': 'Pakistan',\n",
    "    'Maroc': 'Morocco',\n",
    "    'Nederland': 'Netherlands',\n",
    "    'България': 'Bulgaria',\n",
    "    'Shqipëria': 'Albania',\n",
    "    '日本 (Japan)': 'Japan',\n",
    "    'Россия': 'Russia',\n",
    "    'Македонија': 'Macedonia',\n",
    "    'Latvija': 'Latvia',\n",
    "    'Georgia / საქართველო': 'Georgia',\n",
    "    'México': 'Mexico',\n",
    "    'Lëtzebuerg': 'Luxembourg',\n",
    "    'Sverige': 'Sweden',\n",
    "    'Lietuva': 'Lithuania',\n",
    "    'Κύπρος': 'Cyprus',\n",
    "    'Deutschland': 'Germany',\n",
    "    'Việt Nam': 'Vietnam',\n",
    "    'ประเทศไทย': 'Thailand',\n",
    "    'Bosna i Hercegovina': 'Bosnia and Herzegovina',\n",
    "    '대한민국': 'South Korea',\n",
    "    'Ελλάδα': 'Greece',\n",
    "    'ایران': 'Iran',\n",
    "    'Србија (Serbia)': 'Serbia',\n",
    "    'Danmark': 'Denmark',\n",
    "    'Беларусь': 'Belarus',\n",
    "    'Österreich': 'Austria',\n",
    "    'Egypt / مصر': 'Egypt',\n",
    "    'Україна': 'Ukraine',\n",
    "    'Slovensko': 'Slovenia',\n",
    "    'Türkiye': 'Turkey',\n",
    "    'البحرين': 'Bahrain',\n",
    "    'Eesti': 'Estonia',\n",
    "    'لبنان  Lebanon': 'Lebanon',\n",
    "    'Jordan / الأُرْدُن': 'Jordan',\n",
    "    'Kuwait / الكويت': 'Kuwait',\n",
    "    'Italia': 'Italy',\n",
    "    'România': 'Romania',\n",
    "    'China 中国': 'China',\n",
    "    'Brasil': 'Brazil',\n",
    "    'España': 'Spain',\n",
    "    'ישראל': 'Israel',\n",
    "    'Taiwan': 'China'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in city_lookup.keys():\n",
    "    if city_lookup[city]['Country'] in english_names.keys():\n",
    "        city_lookup[city]['Country_English'] = english_names[city_lookup[city]['Country']]\n",
    "    else:\n",
    "        city_lookup[city]['Country_English'] = city_lookup[city]['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can add these new details to our original skyscraper dataset\n",
    "for col in ['Country', 'Country_English', 'Latitude', 'Longitude']:\n",
    "    df[col] = df['City'].apply(lambda x: city_lookup[x][col])\n",
    " \n",
    "state_lookup = get_states()\n",
    "df['State'] = df['City'].apply(lambda x: state_lookup.get(x, 'N/A'))\n",
    "    \n",
    "# Weirdly, when looking at the data manually, I discovered that the geocoding for Cologne did not work, so I filled it in manually. \n",
    "df.loc[df['City'] == 'Cologne', 'Country_English'] = 'Germany'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a bit of cleaning that had to be done on the original skyscraper dataset.  For some of the buildings, there was missing data for the heights, but when reading it in, I noticed that it actually shifted some of the columns left.  So, `Height m` had the `Floors`, `Height ft` had the `Year`, and `Floors` had the `Status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Height m'] = df['Height m'].str.replace(' m', '')\n",
    "df['Height ft'] = df['Height ft'].str.replace(' ft', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_heights = df[df['Status'].isnull()].index\n",
    "\n",
    "df.loc[missing_heights, 'Status'] = df.loc[missing_heights, 'Floors'].copy()\n",
    "df.loc[missing_heights, 'Floors'] = df.loc[missing_heights, 'Height m']\n",
    "df.loc[missing_heights, 'Year'] = df.loc[missing_heights, 'Height ft']\n",
    "df.loc[missing_heights, 'Height m'] = 0\n",
    "df.loc[missing_heights, 'Height ft'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I've converted all the datatypes to floats and ints, as appropriate.  Note that this does not work if you have null values - hence filling in Floors with \"0 floors\". \n",
    "df['Height m'] = df['Height m'].astype(np.float)\n",
    "df['Height ft'] = df['Height ft'].astype(np.float)\n",
    "df['Floors'].fillna(\"0 floors\", inplace=True)\n",
    "df['Floors'] = df['Floors'].str.replace(' floors', '')#.astype(np.int)\n",
    "df['Floors'] = df.Floors.astype(np.int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### This is where you can plot your chloropleth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDP data:\n",
    "\n",
    "I sourced this from the Worldbank website (https://datacatalog.worldbank.org/dataset/world-development-indicators).  I extracted the indicators below for each country, and have saved in `gdp.csv`.  It contains the GDP values below for over 200 economies between 1960 and 2019.  You'll notice that there are several missing years for certain countries.  This again, is typical when working with datasets from multiple sources.  Not all countries release their data, and if they do, they might not provide the results in a similar manner to other countries.  I do not expect you to fill in the missing data here.  Only work with what is here! Eg. UAE only has GDP data from the mid-70s onwards.  That's fine, focus on this period onwards for UAE.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.read_csv('gdp.csv', encoding='latin-1')\n",
    "    \n",
    "indicators = {\n",
    "    'GDP (current US$)': 'NY.GDP.MKTP.CD', \n",
    "    'GDP growth (annual %)': 'NY.GDP.MKTP.KD.ZG',\n",
    "    'GDP per capita (current US$)': 'NY.GDP.PCAP.CD', \n",
    "    'GDP per capita growth (annual %)': 'NY.GDP.PCAP.KD.ZG',\n",
    "    'GDP per capita, PPP (current international $)': 'NY.GDP.PCAP.PP.CD',\n",
    "    'GDP, PPP (current international $)': 'NY.GDP.MKTP.PP.CD'\n",
    "}\n",
    "years = [str(1960 + x) for x in range(60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The countries have different names between the two datasets.  I looked at which countries in the skyscraper dataset do not exist in the GDP dataset, and manually tried to correct for them.  Not all countries were in the GDP dataset, and some had different variations on the name.  \n",
    "\n",
    "Note for N. Koreas and Cote d'Ivoire, the difference also includes a special character!!! This happens, but you just need to be aware of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['Country_English'].isin(dfg['Country Name'])]['Country_English'].unique()\n",
    "\n",
    "gdp_mapping = {\n",
    "    'United States': 'United States of America',\n",
    "    'Russian Federation': 'Russia',\n",
    "    'Korea, Rep.': 'South Korea',\n",
    "    'Iran, Islamic Rep.': 'Iran',\n",
    "    'Venezuela, RB': 'Venezuela',\n",
    "    'Korea, Dem. People\\x92s Rep.': 'North Korea',\n",
    "    'North Macedonia': 'Macedonia',\n",
    "    \"Cote d'Ivoire\": \"Côte d'Ivoire\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gdp_mapping.keys():\n",
    "    dfg.loc[dfg['Country Name'] == g, 'Country Name'] = gdp_mapping[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, you will notice there are only a handful of those which do not match. We can ignore these... \n",
    "df[~df['Country_English'].isin(dfg['Country Name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_it(gdp_data, bldg_data, country, key, indicator):\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    gdp_data.plot(x='Year', y=indicator, ax=ax, label=indicator)\n",
    "    ax2 = ax.twinx()\n",
    "    plt.scatter(x=bldg_data['Year'], y=bldg_data[key], color='red', marker='*', label=key)\n",
    "    plt.title(country)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "countries = ['United States of America', 'China', 'South Africa', 'United Kingdom', 'Australia', 'United Arab Emirates']\n",
    "indicator = 'GDP per capita (current US$)'  # 'GDP per capita growth (annual %)'\n",
    "\n",
    "indicator_cd = indicators[indicator]\n",
    "\n",
    "for country in countries:\n",
    "    key = 'Floors'\n",
    "    num_bldgs = df[(df['Country_English'] == country)].groupby('Year').Building.count().reset_index()\n",
    "    max_height = df[(df['Country_English'] == country)].groupby('Year')[key].max().reset_index()\n",
    "    max_height['Year'] = max_height['Year'].astype(np.int)\n",
    "    dfsa = dfg[(dfg['Country Name'] == country) & (dfg['Indicator Code'] == indicator_cd)][years].T.reset_index()\n",
    "    \n",
    "    dfsa.columns=['Year', indicator]\n",
    "    dfsa.Year = dfsa.Year.astype(np.int)\n",
    "    \n",
    "    plot_it(dfsa, max_height, country, key, indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa = df[df['Country_English'] == 'United States of America']\n",
    "df_usa = df_usa[df_usa['Status'] == 'completed']\n",
    "\n",
    "df_usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa_mean_height = pd.DataFrame(df_usa.groupby('State')['Height m'].mean(), index=None)\n",
    "df_usa_mean_height = df_usa_mean_height.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities; Plot 'New York', 'Los Angeles', 'Chicago', 'San Francisco' and 'Seattle' 'Los Angeles'\n",
    "df_usa_city = df_usa[(df_usa.City == 'New York') | (df_usa.City == 'Los Angeles') | (df_usa.City == 'Chicago')| (df_usa.City == 'San Francisco') | (df_usa.City == 'Seattle')| (df_usa.City == 'Los Angeles')]\n",
    "df_usa_city_height = pd.DataFrame(df_usa_city.groupby('City')['Height m'].max(), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file\n",
    "usa_state_json = json.load(open('USA_states_geojson.json'))\n",
    "# returns geodataframe:\n",
    "usa_df_geo = GeoDataFrame.from_features(usa_state_json['features'])\n",
    "usa_df_geo = usa_df_geo[[\"NAME\", \"geometry\"]]\n",
    "usa_df_geo = usa_df_geo.rename(columns={\"NAME\": \"State\"})\n",
    "\n",
    "# set average tables using dict created in prev cell\n",
    "avg_heights_list = []\n",
    "for state in usa_df_geo.State:\n",
    "    if state in df_usa_mean_height['Height m'].keys():\n",
    "        avg_heights_list.append(df_usa_mean_height['Height m'][state])\n",
    "    else:\n",
    "        avg_heights_list.append(0)\n",
    "        \n",
    "        \n",
    "usa_df_geo[\"Average height m\"] = avg_heights_list\n",
    "usa_df_geo.set_index(usa_df_geo.State, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(usa_df_geo, geojson=usa_df_geo.geometry, locations=usa_df_geo.index, \n",
    "                        color='Average height m',\n",
    "                           color_continuous_scale='turbo',\n",
    "                           range_color=(0, max(avg_heights_list)),\n",
    "                           scope=\"usa\",\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_county_json = json.load(open('gz_2010_us_050_00_500k.json'))\n",
    "usa_county_geo = GeoDataFrame.from_features(usa_county_json['features'])\n",
    "usa_county_geo = usa_county_geo[[\"NAME\", \"geometry\"]]\n",
    "usa_county_geo = usa_county_geo.rename(columns={\"NAME\": \"County\"})\n",
    "usa_county_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "geomerty = []\n",
    "for i in df_usa_city_height.to_dict()['Height m'].keys():\n",
    "    if i in usa_county_geo.County:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cities = []\n",
    "geometry = []\n",
    "for i in usa_county_geo.set_index(\"County\").to_dict()['geometry'].keys():\n",
    "    if i in df_usa_city_height.to_dict()['Height m'].keys():\n",
    "        #print(i, usa_county_geo.set_index(\"County\").to_dict()['geometry'][i])\n",
    "        Cities.append(i)\n",
    "        geomerty.append(usa_county_geo.set_index(\"County\").to_dict()['geometry'][i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Dat{'Cities': Cities, 'geometry': geometry}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Country[['Germany', 'France', 'UK', 'Switzerland', 'Netherlands']]\n",
    "\n",
    "df[((df.Country_English == 'Germany') & (df.Country_English == 'France'))]#& (df.Country == 'UK') & (df.Country == 'Switzerland') & (df.Country == 'Netherlands'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_europe_skyscrappers = df[(df.Country_English == 'Germany') | (df.Country_English == 'France') | (df.Country_English == 'UK') | (df.Country_English == 'Switzerland') | (df.Country == 'Netherlands')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of skyscrappers\n",
    "df_europe_skyscrappers.groupby('Country_English')['Row'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UAE, Japan, and the USA\n",
    "df_uae_jpn_usa = df[(df.Country_English == 'United Arab Emirates') | (df.Country_English == 'Japan') | (df.Country_English == 'United States of America')]\n",
    "df_uae_jpn_usa.groupby('Country_English')['Row'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of skyscrappers per country is shown above. Japan, UAE and USA have 2529 skyscrappers in total. France, Germany and Switzerland have 249 skyscrappers in total. The reason for this is that some European have more or less strict regulations that prevent the construction of high rise buildings. In the 19th Century, skyscrapers first rose to prominence in USA and many European cities were already firmly established with grand historic buildings and public spaces that left little room for large new structures. European cities in the 21st century still try to peserve these historical buildings. \n",
    "\n",
    "Japan, UAE and USA have a relatively high population density compared to European countries. Japan's population density was 320 people per square kilometer as of 1984, while France's population density is 100.10. The vast majority of Europe's urban communities around that time were also more evenly zoned and were not facing the high demand for floor space in key districts that typically drive high rise development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
